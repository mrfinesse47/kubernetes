* 
* ==> Audit <==
* |--------------|---------------------|----------|------------|---------|---------------------|---------------------|
|   Command    |        Args         | Profile  |    User    | Version |     Start Time      |      End Time       |
|--------------|---------------------|----------|------------|---------|---------------------|---------------------|
| start        |                     | minikube | kevinmason | v1.31.2 | 20 Aug 23 21:32 PDT | 20 Aug 23 21:32 PDT |
| dashboard    |                     | minikube | kevinmason | v1.31.2 | 21 Aug 23 18:17 PDT |                     |
| start        |                     | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:21 PDT | 25 Aug 23 11:22 PDT |
| delete       | all                 | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:22 PDT |                     |
| delete       | --all               | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:22 PDT | 25 Aug 23 11:22 PDT |
| start        |                     | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:23 PDT | 25 Aug 23 11:23 PDT |
| update-check |                     | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:26 PDT | 25 Aug 23 11:26 PDT |
| delete       | --all               | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:32 PDT | 25 Aug 23 11:32 PDT |
| start        |                     | minikube | kevinmason | v1.31.2 | 25 Aug 23 11:33 PDT | 25 Aug 23 11:33 PDT |
| update-check |                     | minikube | kevinmason | v1.31.2 | 25 Aug 23 13:58 PDT | 25 Aug 23 13:58 PDT |
| service      | myapp-service --url | minikube | kevinmason | v1.31.2 | 31 Aug 23 19:40 PDT |                     |
| service      | myapp-service --url | minikube | kevinmason | v1.31.2 | 31 Aug 23 19:42 PDT |                     |
|--------------|---------------------|----------|------------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/08/25 11:33:05
Running on machine: Kevins-MBP
Binary: Built with gc go1.21.0 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0825 11:33:05.553689   48115 out.go:296] Setting OutFile to fd 1 ...
I0825 11:33:05.553834   48115 out.go:348] isatty.IsTerminal(1) = true
I0825 11:33:05.553836   48115 out.go:309] Setting ErrFile to fd 2...
I0825 11:33:05.553840   48115 out.go:348] isatty.IsTerminal(2) = true
I0825 11:33:05.553948   48115 root.go:338] Updating PATH: /Users/kevinmason/.minikube/bin
I0825 11:33:05.554312   48115 out.go:303] Setting JSON to false
I0825 11:33:05.580960   48115 start.go:128] hostinfo: {"hostname":"Kevins-MBP","uptime":1869848,"bootTime":1691118537,"procs":530,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.5","kernelVersion":"22.6.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"4864342a-3b1c-5142-80b6-eda14302469f"}
W0825 11:33:05.581030   48115 start.go:136] gopshost.Virtualization returned error: not implemented yet
I0825 11:33:05.590381   48115 out.go:177] 😄  minikube v1.31.2 on Darwin 13.5 (arm64)
I0825 11:33:05.599574   48115 notify.go:220] Checking for updates...
I0825 11:33:05.599971   48115 driver.go:373] Setting default libvirt URI to qemu:///system
I0825 11:33:05.600033   48115 global.go:111] Querying for installed drivers using PATH=/Users/kevinmason/.minikube/bin:/Users/kevinmason/.nvm/versions/node/v16.17.0/bin:/usr/local/bin:/Library/Frameworks/Python.framework/Versions/3.11/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/mysql/bin:/usr/local/mysql/support-files:export DYLD_LIBRARY_PATH="/usr/local/mysql/lib:$PATH":/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin
I0825 11:33:05.600095   48115 global.go:122] vmware default: false priority: 5, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "vmrun": executable file not found in $PATH Reason: Fix:Install vmrun Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/ Version:}
I0825 11:33:05.659636   48115 docker.go:121] docker version: linux-24.0.2:Docker Desktop 4.21.1 (114176)
I0825 11:33:05.659764   48115 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0825 11:33:05.951727   48115 info.go:266] docker info: {ID:a54d1e7c-4bf1-43cd-beb7-f550af625af6 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:2 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:52 OomKillDisable:false NGoroutines:87 SystemTime:2023-08-25 18:33:05.928726926 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:15 KernelVersion:5.15.49-linuxkit-pr OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8232951808 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:24.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID:v1.1.7-0-g860f061 Expected:v1.1.7-0-g860f061} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/kevinmason/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.0] map[Name:compose Path:/Users/kevinmason/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.19.1] map[Name:dev Path:/Users/kevinmason/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/kevinmason/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-extension] ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/Users/kevinmason/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-init] ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.6] map[Name:sbom Path:/Users/kevinmason/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/kevinmason/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/Users/kevinmason/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scout] ShortDescription:Command line tool for Docker Scout Vendor:Docker Inc. Version:0.16.1]] Warnings:<nil>}}
I0825 11:33:05.951798   48115 global.go:122] docker default: true priority: 9, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0825 11:33:05.951903   48115 global.go:122] podman default: true priority: 3, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "podman": executable file not found in $PATH Reason: Fix:Install Podman Doc:https://minikube.sigs.k8s.io/docs/drivers/podman/ Version:}
I0825 11:33:05.952127   48115 global.go:122] ssh default: false priority: 4, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0825 11:33:05.952162   48115 global.go:122] hyperkit default: true priority: 8, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "hyperkit": executable file not found in $PATH Reason: Fix:Run 'brew install hyperkit' Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/hyperkit/ Version:}
I0825 11:33:05.952198   48115 global.go:122] parallels default: true priority: 7, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "prlctl": executable file not found in $PATH Reason: Fix:Install Parallels Desktop for Mac Doc:https://minikube.sigs.k8s.io/docs/drivers/parallels/ Version:}
I0825 11:33:05.952233   48115 global.go:122] qemu2 default: true priority: 7, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "qemu-system-aarch64": executable file not found in $PATH Reason: Fix:Install qemu-system Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/qemu/ Version:}
W0825 11:33:05.956145   48115 virtualbox.go:101] unable to get virtualbox version, returned: <nil>
I0825 11:33:05.956161   48115 global.go:122] virtualbox default: true priority: 6, state: {Installed:true Healthy:false Running:false NeedsImprovement:false Error:"/usr/local/bin/VBoxManage --version" returned: <nil> Reason: Fix:Restart VirtualBox, or upgrade to the latest version of VirtualBox Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/virtualbox/ Version:}
I0825 11:33:05.956355   48115 driver.go:308] not recommending "ssh" due to default: false
I0825 11:33:05.956357   48115 driver.go:303] not recommending "virtualbox" due to health: "/usr/local/bin/VBoxManage --version" returned: <nil>
I0825 11:33:05.956378   48115 driver.go:343] Picked: docker
I0825 11:33:05.956385   48115 driver.go:344] Alternatives: [ssh]
I0825 11:33:05.956387   48115 driver.go:345] Rejects: [vmware podman hyperkit parallels qemu2 virtualbox]
I0825 11:33:05.965364   48115 out.go:177] ✨  Automatically selected the docker driver
I0825 11:33:05.969350   48115 start.go:298] selected driver: docker
I0825 11:33:05.969356   48115 start.go:902] validating driver "docker" against <nil>
I0825 11:33:05.969362   48115 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0825 11:33:05.969434   48115 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0825 11:33:06.056891   48115 info.go:266] docker info: {ID:a54d1e7c-4bf1-43cd-beb7-f550af625af6 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:2 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:52 OomKillDisable:false NGoroutines:87 SystemTime:2023-08-25 18:33:06.04776676 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:15 KernelVersion:5.15.49-linuxkit-pr OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8232951808 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:24.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID:v1.1.7-0-g860f061 Expected:v1.1.7-0-g860f061} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/kevinmason/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.0] map[Name:compose Path:/Users/kevinmason/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.19.1] map[Name:dev Path:/Users/kevinmason/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/kevinmason/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-extension] ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/Users/kevinmason/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-init] ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.6] map[Name:sbom Path:/Users/kevinmason/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/kevinmason/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/Users/kevinmason/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scout] ShortDescription:Command line tool for Docker Scout Vendor:Docker Inc. Version:0.16.1]] Warnings:<nil>}}
I0825 11:33:06.057020   48115 start_flags.go:305] no existing cluster config was found, will generate one from the flags 
I0825 11:33:06.057325   48115 start_flags.go:382] Using suggested 4000MB memory alloc based on sys=16384MB, container=7851MB
I0825 11:33:06.057626   48115 start_flags.go:901] Wait components to verify : map[apiserver:true system_pods:true]
I0825 11:33:06.061400   48115 out.go:177] 📌  Using Docker Desktop driver with root privileges
I0825 11:33:06.064568   48115 cni.go:84] Creating CNI manager for ""
I0825 11:33:06.064723   48115 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0825 11:33:06.064726   48115 start_flags.go:314] Found "bridge CNI" CNI - setting NetworkPlugin=cni
I0825 11:33:06.064730   48115 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0825 11:33:06.068423   48115 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I0825 11:33:06.075570   48115 cache.go:122] Beginning downloading kic base image for docker with docker
I0825 11:33:06.079325   48115 out.go:177] 🚜  Pulling base image ...
I0825 11:33:06.086315   48115 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0825 11:33:06.086343   48115 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon
I0825 11:33:06.086370   48115 preload.go:148] Found local preload: /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4
I0825 11:33:06.086376   48115 cache.go:57] Caching tarball of preloaded images
I0825 11:33:06.086508   48115 preload.go:174] Found /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I0825 11:33:06.086728   48115 cache.go:60] Finished verifying existence of preloaded tar for  v1.27.4 on docker
I0825 11:33:06.087542   48115 profile.go:148] Saving config to /Users/kevinmason/.minikube/profiles/minikube/config.json ...
I0825 11:33:06.087632   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/config.json: {Name:mk0b816cce9d3d4f1c392b4b07003614f4a605d9 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:06.135084   48115 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon, skipping pull
I0825 11:33:06.135104   48115 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 exists in daemon, skipping load
I0825 11:33:06.135351   48115 cache.go:195] Successfully downloaded all kic artifacts
I0825 11:33:06.135558   48115 start.go:365] acquiring machines lock for minikube: {Name:mke5a11e3023f612ec910c35f9ceded2d6acb38c Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0825 11:33:06.135629   48115 start.go:369] acquired machines lock for "minikube" in 60.625µs
I0825 11:33:06.135653   48115 start.go:93] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0} &{Name: IP: Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}
I0825 11:33:06.135709   48115 start.go:125] createHost starting for "" (driver="docker")
I0825 11:33:06.140517   48115 out.go:204] 🔥  Creating docker container (CPUs=2, Memory=4000MB) ...
I0825 11:33:06.140907   48115 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I0825 11:33:06.140933   48115 client.go:168] LocalClient.Create starting
I0825 11:33:06.141432   48115 main.go:141] libmachine: Reading certificate data from /Users/kevinmason/.minikube/certs/ca.pem
I0825 11:33:06.141660   48115 main.go:141] libmachine: Decoding PEM data...
I0825 11:33:06.141666   48115 main.go:141] libmachine: Parsing certificate...
I0825 11:33:06.142182   48115 main.go:141] libmachine: Reading certificate data from /Users/kevinmason/.minikube/certs/cert.pem
I0825 11:33:06.142283   48115 main.go:141] libmachine: Decoding PEM data...
I0825 11:33:06.142287   48115 main.go:141] libmachine: Parsing certificate...
I0825 11:33:06.144698   48115 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0825 11:33:06.194667   48115 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0825 11:33:06.194747   48115 network_create.go:281] running [docker network inspect minikube] to gather additional debugging logs...
I0825 11:33:06.194759   48115 cli_runner.go:164] Run: docker network inspect minikube
W0825 11:33:06.241849   48115 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0825 11:33:06.241865   48115 network_create.go:284] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I0825 11:33:06.241881   48115 network_create.go:286] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I0825 11:33:06.241945   48115 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0825 11:33:06.294478   48115 network.go:209] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0x1400101f2e0}
I0825 11:33:06.294728   48115 network_create.go:123] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 65535 ...
I0825 11:33:06.294784   48115 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=65535 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0825 11:33:06.385635   48115 network_create.go:107] docker network minikube 192.168.49.0/24 created
I0825 11:33:06.385881   48115 kic.go:117] calculated static IP "192.168.49.2" for the "minikube" container
I0825 11:33:06.385973   48115 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0825 11:33:06.431176   48115 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0825 11:33:06.472566   48115 oci.go:103] Successfully created a docker volume minikube
I0825 11:33:06.472662   48115 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -d /var/lib
I0825 11:33:06.740913   48115 oci.go:107] Successfully prepared a docker volume minikube
I0825 11:33:06.740942   48115 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0825 11:33:06.740954   48115 kic.go:190] Starting extracting preloaded images to volume ...
I0825 11:33:06.741330   48115 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -I lz4 -xf /preloaded.tar -C /extractDir
W0825 11:33:06.869068   48115 cli_runner.go:211] docker run --rm --entrypoint /usr/bin/tar -v /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -I lz4 -xf /preloaded.tar -C /extractDir returned with exit code 125
I0825 11:33:06.869105   48115 kic.go:197] Unable to extract preloaded tarball to volume: docker run --rm --entrypoint /usr/bin/tar -v /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -I lz4 -xf /preloaded.tar -C /extractDir: exit status 125
stdout:

stderr:
docker: Error response from daemon: Mounts denied: 
The path /Users/kevinmason/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4 is not shared from the host and is not known to Docker.
You can configure shared paths from Docker -> Preferences... -> Resources -> File Sharing.
See https://docs.docker.com/desktop/mac for more info.
time="2023-08-25T11:33:06-07:00" level=error msg="error waiting for container: "
I0825 11:33:06.869250   48115 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0825 11:33:07.001417   48115 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=4000mb --memory-swap=4000mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631
I0825 11:33:07.241059   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0825 11:33:07.287953   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:07.330653   48115 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0825 11:33:07.405490   48115 oci.go:144] the created container "minikube" has a running status.
I0825 11:33:07.405760   48115 kic.go:221] Creating ssh key for kic: /Users/kevinmason/.minikube/machines/minikube/id_rsa...
I0825 11:33:07.487710   48115 kic_runner.go:191] docker (temp): /Users/kevinmason/.minikube/machines/minikube/id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0825 11:33:07.538362   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:07.588868   48115 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0825 11:33:07.588889   48115 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0825 11:33:07.677742   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:07.724649   48115 machine.go:88] provisioning docker machine ...
I0825 11:33:07.724697   48115 ubuntu.go:169] provisioning hostname "minikube"
I0825 11:33:07.725824   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:07.768925   48115 main.go:141] libmachine: Using SSH client type: native
I0825 11:33:07.769294   48115 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100a1f730] 0x100a21ea0 <nil>  [] 0s} 127.0.0.1 61129 <nil> <nil>}
I0825 11:33:07.769302   48115 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0825 11:33:07.892231   48115 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0825 11:33:07.892341   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:07.934297   48115 main.go:141] libmachine: Using SSH client type: native
I0825 11:33:07.934582   48115 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100a1f730] 0x100a21ea0 <nil>  [] 0s} 127.0.0.1 61129 <nil> <nil>}
I0825 11:33:07.934588   48115 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0825 11:33:08.046828   48115 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0825 11:33:08.046839   48115 ubuntu.go:175] set auth options {CertDir:/Users/kevinmason/.minikube CaCertPath:/Users/kevinmason/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/kevinmason/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/kevinmason/.minikube/machines/server.pem ServerKeyPath:/Users/kevinmason/.minikube/machines/server-key.pem ClientKeyPath:/Users/kevinmason/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/kevinmason/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/kevinmason/.minikube}
I0825 11:33:08.046851   48115 ubuntu.go:177] setting up certificates
I0825 11:33:08.046855   48115 provision.go:83] configureAuth start
I0825 11:33:08.046948   48115 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0825 11:33:08.091510   48115 provision.go:138] copyHostCerts
I0825 11:33:08.091617   48115 exec_runner.go:144] found /Users/kevinmason/.minikube/ca.pem, removing ...
I0825 11:33:08.091622   48115 exec_runner.go:203] rm: /Users/kevinmason/.minikube/ca.pem
I0825 11:33:08.091752   48115 exec_runner.go:151] cp: /Users/kevinmason/.minikube/certs/ca.pem --> /Users/kevinmason/.minikube/ca.pem (1090 bytes)
I0825 11:33:08.091936   48115 exec_runner.go:144] found /Users/kevinmason/.minikube/cert.pem, removing ...
I0825 11:33:08.091937   48115 exec_runner.go:203] rm: /Users/kevinmason/.minikube/cert.pem
I0825 11:33:08.091979   48115 exec_runner.go:151] cp: /Users/kevinmason/.minikube/certs/cert.pem --> /Users/kevinmason/.minikube/cert.pem (1131 bytes)
I0825 11:33:08.092073   48115 exec_runner.go:144] found /Users/kevinmason/.minikube/key.pem, removing ...
I0825 11:33:08.092074   48115 exec_runner.go:203] rm: /Users/kevinmason/.minikube/key.pem
I0825 11:33:08.092109   48115 exec_runner.go:151] cp: /Users/kevinmason/.minikube/certs/key.pem --> /Users/kevinmason/.minikube/key.pem (1675 bytes)
I0825 11:33:08.092292   48115 provision.go:112] generating server cert: /Users/kevinmason/.minikube/machines/server.pem ca-key=/Users/kevinmason/.minikube/certs/ca.pem private-key=/Users/kevinmason/.minikube/certs/ca-key.pem org=kevinmason.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0825 11:33:08.190484   48115 provision.go:172] copyRemoteCerts
I0825 11:33:08.190825   48115 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0825 11:33:08.190860   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:08.235618   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:08.324244   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1090 bytes)
I0825 11:33:08.347850   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/machines/server.pem --> /etc/docker/server.pem (1212 bytes)
I0825 11:33:08.367752   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0825 11:33:08.387451   48115 provision.go:86] duration metric: configureAuth took 340.579ms
I0825 11:33:08.387461   48115 ubuntu.go:193] setting minikube options for container-runtime
I0825 11:33:08.387593   48115 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0825 11:33:08.387644   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:08.431348   48115 main.go:141] libmachine: Using SSH client type: native
I0825 11:33:08.431631   48115 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100a1f730] 0x100a21ea0 <nil>  [] 0s} 127.0.0.1 61129 <nil> <nil>}
I0825 11:33:08.431638   48115 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0825 11:33:08.543594   48115 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0825 11:33:08.543603   48115 ubuntu.go:71] root file system type: overlay
I0825 11:33:08.543693   48115 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0825 11:33:08.543812   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:08.592024   48115 main.go:141] libmachine: Using SSH client type: native
I0825 11:33:08.592364   48115 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100a1f730] 0x100a21ea0 <nil>  [] 0s} 127.0.0.1 61129 <nil> <nil>}
I0825 11:33:08.592404   48115 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0825 11:33:08.719663   48115 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0825 11:33:08.719788   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:08.766065   48115 main.go:141] libmachine: Using SSH client type: native
I0825 11:33:08.766366   48115 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100a1f730] 0x100a21ea0 <nil>  [] 0s} 127.0.0.1 61129 <nil> <nil>}
I0825 11:33:08.766373   48115 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0825 11:33:09.378791   48115 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2023-07-07 14:51:01.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2023-08-25 18:33:08.717562011 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0825 11:33:09.378818   48115 machine.go:91] provisioned docker machine in 1.654136625s
I0825 11:33:09.378828   48115 client.go:171] LocalClient.Create took 3.237883334s
I0825 11:33:09.378852   48115 start.go:167] duration metric: libmachine.API.Create for "minikube" took 3.237932833s
I0825 11:33:09.378859   48115 start.go:300] post-start starting for "minikube" (driver="docker")
I0825 11:33:09.379198   48115 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0825 11:33:09.379900   48115 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0825 11:33:09.379971   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:09.429820   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:09.515744   48115 ssh_runner.go:195] Run: cat /etc/os-release
I0825 11:33:09.519541   48115 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0825 11:33:09.519554   48115 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0825 11:33:09.519559   48115 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0825 11:33:09.519561   48115 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I0825 11:33:09.519566   48115 filesync.go:126] Scanning /Users/kevinmason/.minikube/addons for local assets ...
I0825 11:33:09.519656   48115 filesync.go:126] Scanning /Users/kevinmason/.minikube/files for local assets ...
I0825 11:33:09.519683   48115 start.go:303] post-start completed in 140.820708ms
I0825 11:33:09.520056   48115 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0825 11:33:09.566952   48115 profile.go:148] Saving config to /Users/kevinmason/.minikube/profiles/minikube/config.json ...
I0825 11:33:09.567401   48115 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0825 11:33:09.567446   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:09.615965   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:09.697652   48115 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0825 11:33:09.703064   48115 start.go:128] duration metric: createHost completed in 3.567338875s
I0825 11:33:09.703075   48115 start.go:83] releasing machines lock for "minikube", held for 3.567434125s
I0825 11:33:09.703137   48115 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0825 11:33:09.744965   48115 ssh_runner.go:195] Run: cat /version.json
I0825 11:33:09.745023   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:09.745625   48115 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0825 11:33:09.745810   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:09.790773   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:09.790786   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:09.870532   48115 ssh_runner.go:195] Run: systemctl --version
I0825 11:33:10.052708   48115 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0825 11:33:10.060008   48115 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0825 11:33:10.084835   48115 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0825 11:33:10.085038   48115 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0825 11:33:10.106197   48115 cni.go:262] disabled [/etc/cni/net.d/100-crio-bridge.conf, /etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0825 11:33:10.106246   48115 start.go:466] detecting cgroup driver to use...
I0825 11:33:10.106279   48115 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0825 11:33:10.107006   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0825 11:33:10.121015   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0825 11:33:10.130429   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0825 11:33:10.139642   48115 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0825 11:33:10.139933   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0825 11:33:10.149134   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0825 11:33:10.158825   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0825 11:33:10.168182   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0825 11:33:10.176834   48115 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0825 11:33:10.185667   48115 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0825 11:33:10.194784   48115 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0825 11:33:10.202395   48115 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0825 11:33:10.209947   48115 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0825 11:33:10.269270   48115 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0825 11:33:10.335969   48115 start.go:466] detecting cgroup driver to use...
I0825 11:33:10.335992   48115 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0825 11:33:10.336180   48115 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0825 11:33:10.347876   48115 cruntime.go:276] skipping containerd shutdown because we are bound to it
I0825 11:33:10.348048   48115 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0825 11:33:10.358845   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0825 11:33:10.373892   48115 ssh_runner.go:195] Run: which cri-dockerd
I0825 11:33:10.378162   48115 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0825 11:33:10.386981   48115 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0825 11:33:10.405089   48115 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0825 11:33:10.467078   48115 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0825 11:33:10.534495   48115 docker.go:535] configuring docker to use "cgroupfs" as cgroup driver...
I0825 11:33:10.534524   48115 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0825 11:33:10.550446   48115 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0825 11:33:10.617570   48115 ssh_runner.go:195] Run: sudo systemctl restart docker
I0825 11:33:10.862466   48115 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0825 11:33:10.926915   48115 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0825 11:33:10.988081   48115 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0825 11:33:11.048842   48115 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0825 11:33:11.107779   48115 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0825 11:33:11.119850   48115 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0825 11:33:11.179872   48115 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0825 11:33:11.256991   48115 start.go:513] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0825 11:33:11.257844   48115 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0825 11:33:11.262281   48115 start.go:534] Will wait 60s for crictl version
I0825 11:33:11.262354   48115 ssh_runner.go:195] Run: which crictl
I0825 11:33:11.266041   48115 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0825 11:33:11.307069   48115 start.go:550] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.4
RuntimeApiVersion:  v1
I0825 11:33:11.307188   48115 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0825 11:33:11.332723   48115 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0825 11:33:11.363867   48115 out.go:204] 🐳  Preparing Kubernetes v1.27.4 on Docker 24.0.4 ...
I0825 11:33:11.364072   48115 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0825 11:33:11.484119   48115 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0825 11:33:11.484474   48115 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0825 11:33:11.488652   48115 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0825 11:33:11.499195   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0825 11:33:11.546132   48115 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0825 11:33:11.546181   48115 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0825 11:33:11.563567   48115 docker.go:636] Got preloaded images: -- stdout --
mrfinesse47/kub-first-app:latest
nginx:latest
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0825 11:33:11.564506   48115 docker.go:566] Images already preloaded, skipping extraction
I0825 11:33:11.564831   48115 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0825 11:33:11.580802   48115 docker.go:636] Got preloaded images: -- stdout --
mrfinesse47/kub-first-app:latest
nginx:latest
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0825 11:33:11.580821   48115 cache_images.go:84] Images are preloaded, skipping loading
I0825 11:33:11.580879   48115 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0825 11:33:11.631647   48115 cni.go:84] Creating CNI manager for ""
I0825 11:33:11.631654   48115 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0825 11:33:11.632172   48115 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0825 11:33:11.632190   48115 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.27.4 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0825 11:33:11.632296   48115 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.27.4
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0825 11:33:11.632357   48115 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.27.4/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0825 11:33:11.632464   48115 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.27.4
I0825 11:33:11.640202   48115 binaries.go:44] Found k8s binaries, skipping transfer
I0825 11:33:11.640355   48115 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0825 11:33:11.647524   48115 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0825 11:33:11.660892   48115 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0825 11:33:11.674030   48115 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2091 bytes)
I0825 11:33:11.688706   48115 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0825 11:33:11.692658   48115 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0825 11:33:11.703702   48115 certs.go:56] Setting up /Users/kevinmason/.minikube/profiles/minikube for IP: 192.168.49.2
I0825 11:33:11.704060   48115 certs.go:190] acquiring lock for shared ca certs: {Name:mkdd4474bf9dec236ed740a35c897ae7173cb86d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:11.705677   48115 certs.go:199] skipping minikubeCA CA generation: /Users/kevinmason/.minikube/ca.key
I0825 11:33:11.706134   48115 certs.go:199] skipping proxyClientCA CA generation: /Users/kevinmason/.minikube/proxy-client-ca.key
I0825 11:33:11.706250   48115 certs.go:319] generating minikube-user signed cert: /Users/kevinmason/.minikube/profiles/minikube/client.key
I0825 11:33:11.706272   48115 crypto.go:68] Generating cert /Users/kevinmason/.minikube/profiles/minikube/client.crt with IP's: []
I0825 11:33:11.890511   48115 crypto.go:156] Writing cert to /Users/kevinmason/.minikube/profiles/minikube/client.crt ...
I0825 11:33:11.890532   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/client.crt: {Name:mk58c1bca115c5dec5dc85463b27ca54dc460c0b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:11.891089   48115 crypto.go:164] Writing key to /Users/kevinmason/.minikube/profiles/minikube/client.key ...
I0825 11:33:11.891092   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/client.key: {Name:mk704dee64b6178b9c0917a2d571e07967f491b9 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:11.891228   48115 certs.go:319] generating minikube signed cert: /Users/kevinmason/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0825 11:33:11.891244   48115 crypto.go:68] Generating cert /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt.dd3b5fb2 with IP's: [192.168.49.2 10.96.0.1 127.0.0.1 10.0.0.1]
I0825 11:33:11.989796   48115 crypto.go:156] Writing cert to /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt.dd3b5fb2 ...
I0825 11:33:11.989804   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt.dd3b5fb2: {Name:mk57fd3b29958109d2c29cee4fc1bfedd5f4858c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:11.990026   48115 crypto.go:164] Writing key to /Users/kevinmason/.minikube/profiles/minikube/apiserver.key.dd3b5fb2 ...
I0825 11:33:11.990028   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/apiserver.key.dd3b5fb2: {Name:mk6530f8c74b763add14d1c56c3c8715690b07be Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:11.990110   48115 certs.go:337] copying /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt.dd3b5fb2 -> /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt
I0825 11:33:11.990482   48115 certs.go:341] copying /Users/kevinmason/.minikube/profiles/minikube/apiserver.key.dd3b5fb2 -> /Users/kevinmason/.minikube/profiles/minikube/apiserver.key
I0825 11:33:11.990577   48115 certs.go:319] generating aggregator signed cert: /Users/kevinmason/.minikube/profiles/minikube/proxy-client.key
I0825 11:33:11.990583   48115 crypto.go:68] Generating cert /Users/kevinmason/.minikube/profiles/minikube/proxy-client.crt with IP's: []
I0825 11:33:12.116202   48115 crypto.go:156] Writing cert to /Users/kevinmason/.minikube/profiles/minikube/proxy-client.crt ...
I0825 11:33:12.116209   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/proxy-client.crt: {Name:mk878389846e319ad57fb9b4ae9e202690c4c7d8 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:12.116436   48115 crypto.go:164] Writing key to /Users/kevinmason/.minikube/profiles/minikube/proxy-client.key ...
I0825 11:33:12.116438   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.minikube/profiles/minikube/proxy-client.key: {Name:mkf83abb50e19a7fb91232da0c072a352066e928 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:12.116731   48115 certs.go:437] found cert: /Users/kevinmason/.minikube/certs/Users/kevinmason/.minikube/certs/ca-key.pem (1675 bytes)
I0825 11:33:12.116758   48115 certs.go:437] found cert: /Users/kevinmason/.minikube/certs/Users/kevinmason/.minikube/certs/ca.pem (1090 bytes)
I0825 11:33:12.116777   48115 certs.go:437] found cert: /Users/kevinmason/.minikube/certs/Users/kevinmason/.minikube/certs/cert.pem (1131 bytes)
I0825 11:33:12.116795   48115 certs.go:437] found cert: /Users/kevinmason/.minikube/certs/Users/kevinmason/.minikube/certs/key.pem (1675 bytes)
I0825 11:33:12.117117   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0825 11:33:12.172102   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0825 11:33:12.197743   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0825 11:33:12.218436   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0825 11:33:12.236132   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0825 11:33:12.253850   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0825 11:33:12.272040   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0825 11:33:12.290162   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0825 11:33:12.307710   48115 ssh_runner.go:362] scp /Users/kevinmason/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0825 11:33:12.328323   48115 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0825 11:33:12.342661   48115 ssh_runner.go:195] Run: openssl version
I0825 11:33:12.348214   48115 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0825 11:33:12.357518   48115 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0825 11:33:12.361961   48115 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Aug 21 04:32 /usr/share/ca-certificates/minikubeCA.pem
I0825 11:33:12.362097   48115 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0825 11:33:12.368774   48115 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0825 11:33:12.377409   48115 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0825 11:33:12.381250   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0825 11:33:12.387887   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0825 11:33:12.393905   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0825 11:33:12.399844   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0825 11:33:12.405820   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0825 11:33:12.411709   48115 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0825 11:33:12.417487   48115 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0825 11:33:12.417604   48115 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0825 11:33:12.433940   48115 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0825 11:33:12.441640   48115 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0825 11:33:12.442628   48115 kubeadm.go:636] restartCluster start
I0825 11:33:12.442741   48115 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0825 11:33:12.450700   48115 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0825 11:33:12.450814   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0825 11:33:12.518971   48115 kubeconfig.go:135] verify returned: extract IP: "minikube" does not appear in /Users/kevinmason/.kube/config
I0825 11:33:12.519219   48115 kubeconfig.go:146] "minikube" context is missing from /Users/kevinmason/.kube/config - will repair!
I0825 11:33:12.519605   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.kube/config: {Name:mkf8acc1c20e5852df0fa121fdba2a23384dbc0f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:12.527097   48115 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0825 11:33:12.536503   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:12.536574   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:12.545705   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:12.545714   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:12.545777   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:12.553649   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:13.055492   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:13.056188   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:13.091332   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:13.558706   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:13.559583   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:13.595203   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:14.053958   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:14.054519   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:14.091888   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:14.553827   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:14.554090   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:14.564323   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:15.055744   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:15.056374   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:15.090292   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:15.554195   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:15.560531   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:15.578721   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:16.054858   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:16.055463   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:16.092315   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:16.554148   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:16.554808   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:16.583833   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:17.054717   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:17.055405   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:17.091506   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:17.554059   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:17.554492   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:17.599296   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:18.054930   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:18.055601   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:18.091196   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:18.556684   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:18.557101   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:18.599603   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:19.054625   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:19.055238   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:19.090945   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:19.554354   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:19.554992   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:19.590250   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:20.054891   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:20.055535   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:20.096635   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:20.554924   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:20.562445   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:20.600737   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:21.054890   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:21.055509   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:21.090110   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:21.555166   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:21.556290   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:21.587611   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:22.054773   48115 api_server.go:166] Checking apiserver status ...
I0825 11:33:22.055077   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0825 11:33:22.090893   48115 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0825 11:33:22.536818   48115 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0825 11:33:22.536870   48115 kubeadm.go:1128] stopping kube-system containers ...
I0825 11:33:22.537429   48115 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0825 11:33:22.594106   48115 docker.go:462] Stopping containers: [ce11e1b4a449 b2d92459f37e e4de3d836693 fb6965bb0c0a b580e467fa2a aa0e4224dc5c 4c242088ed59 c3ca775f81dd 95aec4b7fb14 1fc79a4103fe aae319237635 38d3500bcd83 0ce01b731518 1087a9274145 ab85b2b2e539 f9ec9dc0ba46 d8c61e713379 62caf13fd1ed 3e300096392d bdbc09f57a8c d68559d75619 4331560e0496 eeae770e67dd 65ee874af945 104481ca8338 daaddf5c11e4 39b6dc60811d]
I0825 11:33:22.594483   48115 ssh_runner.go:195] Run: docker stop ce11e1b4a449 b2d92459f37e e4de3d836693 fb6965bb0c0a b580e467fa2a aa0e4224dc5c 4c242088ed59 c3ca775f81dd 95aec4b7fb14 1fc79a4103fe aae319237635 38d3500bcd83 0ce01b731518 1087a9274145 ab85b2b2e539 f9ec9dc0ba46 d8c61e713379 62caf13fd1ed 3e300096392d bdbc09f57a8c d68559d75619 4331560e0496 eeae770e67dd 65ee874af945 104481ca8338 daaddf5c11e4 39b6dc60811d
I0825 11:33:22.620233   48115 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0825 11:33:22.632527   48115 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0825 11:33:22.640258   48115 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0825 11:33:22.640420   48115 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0825 11:33:22.648929   48115 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0825 11:33:22.648948   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:22.695572   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:23.401578   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:23.509452   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:23.552201   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:23.591445   48115 api_server.go:52] waiting for apiserver process to appear ...
I0825 11:33:23.591602   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0825 11:33:23.621614   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0825 11:33:24.132890   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0825 11:33:24.632403   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0825 11:33:24.645921   48115 api_server.go:72] duration metric: took 1.054474292s to wait for apiserver process to appear ...
I0825 11:33:24.645945   48115 api_server.go:88] waiting for apiserver healthz status ...
I0825 11:33:24.645968   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:26.699023   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0825 11:33:26.699040   48115 api_server.go:103] status: https://127.0.0.1:61133/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0825 11:33:26.699050   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:26.710750   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0825 11:33:26.710763   48115 api_server.go:103] status: https://127.0.0.1:61133/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0825 11:33:27.213331   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:27.240523   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0825 11:33:27.240563   48115 api_server.go:103] status: https://127.0.0.1:61133/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0825 11:33:27.712347   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:27.718226   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0825 11:33:27.718246   48115 api_server.go:103] status: https://127.0.0.1:61133/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0825 11:33:28.211885   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:28.217448   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 200:
ok
I0825 11:33:28.229026   48115 api_server.go:141] control plane version: v1.27.4
I0825 11:33:28.229043   48115 api_server.go:131] duration metric: took 3.583082583s to wait for apiserver health ...
I0825 11:33:28.229051   48115 cni.go:84] Creating CNI manager for ""
I0825 11:33:28.229065   48115 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0825 11:33:28.234565   48115 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I0825 11:33:28.241178   48115 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0825 11:33:28.253839   48115 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0825 11:33:28.318885   48115 system_pods.go:43] waiting for kube-system pods to appear ...
I0825 11:33:28.328765   48115 system_pods.go:59] 7 kube-system pods found
I0825 11:33:28.328786   48115 system_pods.go:61] "coredns-5d78c9869d-h4kwc" [4f77c13d-0ff2-46d1-8522-a5eb4023ebef] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0825 11:33:28.328795   48115 system_pods.go:61] "etcd-minikube" [0409753f-7e4a-4f5f-ac49-1e905a247e72] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0825 11:33:28.328802   48115 system_pods.go:61] "kube-apiserver-minikube" [5cb5f97d-0c4e-4d6c-9c4e-544fef89ba89] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0825 11:33:28.328810   48115 system_pods.go:61] "kube-controller-manager-minikube" [72c97442-cd76-4062-ac31-787a0f72451b] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0825 11:33:28.328816   48115 system_pods.go:61] "kube-proxy-nqbsc" [1f9278a2-6f04-42fd-8270-5fdee87ec062] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0825 11:33:28.328822   48115 system_pods.go:61] "kube-scheduler-minikube" [c0dd31ac-e2ce-41c0-aaf4-c7e79a5ed43d] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0825 11:33:28.328828   48115 system_pods.go:61] "storage-provisioner" [f629fc57-ef1b-4b6f-a816-d012ca8331d1] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0825 11:33:28.328834   48115 system_pods.go:74] duration metric: took 9.93975ms to wait for pod list to return data ...
I0825 11:33:28.328841   48115 node_conditions.go:102] verifying NodePressure condition ...
I0825 11:33:28.332026   48115 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I0825 11:33:28.332039   48115 node_conditions.go:123] node cpu capacity is 4
I0825 11:33:28.332048   48115 node_conditions.go:105] duration metric: took 3.202709ms to run NodePressure ...
I0825 11:33:28.332062   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0825 11:33:28.643923   48115 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0825 11:33:28.653559   48115 ops.go:34] apiserver oom_adj: -16
I0825 11:33:28.653577   48115 kubeadm.go:640] restartCluster took 16.210901333s
I0825 11:33:28.653587   48115 kubeadm.go:406] StartCluster complete in 16.23606825s
I0825 11:33:28.653609   48115 settings.go:142] acquiring lock: {Name:mk80201343e09c43caf8960bc55200c6e53f6b99 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:28.655444   48115 settings.go:150] Updating kubeconfig:  /Users/kevinmason/.kube/config
I0825 11:33:28.658189   48115 lock.go:35] WriteFile acquiring /Users/kevinmason/.kube/config: {Name:mkf8acc1c20e5852df0fa121fdba2a23384dbc0f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0825 11:33:28.658713   48115 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.4/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0825 11:33:28.658946   48115 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0825 11:33:28.659117   48115 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I0825 11:33:28.659245   48115 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0825 11:33:28.659259   48115 addons.go:231] Setting addon storage-provisioner=true in "minikube"
I0825 11:33:28.659318   48115 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0825 11:33:28.659335   48115 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0825 11:33:28.659733   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:28.661319   48115 host.go:66] Checking if "minikube" exists ...
I0825 11:33:28.664302   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:28.713128   48115 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0825 11:33:28.713162   48115 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}
I0825 11:33:28.720102   48115 out.go:177] 🔎  Verifying Kubernetes components...
I0825 11:33:28.730445   48115 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0825 11:33:28.737334   48115 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0825 11:33:28.740305   48115 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0825 11:33:28.740312   48115 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0825 11:33:28.740386   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:28.743189   48115 addons.go:231] Setting addon default-storageclass=true in "minikube"
I0825 11:33:28.743232   48115 host.go:66] Checking if "minikube" exists ...
I0825 11:33:28.743479   48115 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0825 11:33:28.790900   48115 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0825 11:33:28.790917   48115 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0825 11:33:28.790928   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:28.791017   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0825 11:33:28.834967   48115 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:61129 SSHKeyPath:/Users/kevinmason/.minikube/machines/minikube/id_rsa Username:docker}
I0825 11:33:28.848531   48115 start.go:874] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0825 11:33:28.848578   48115 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0825 11:33:28.891681   48115 api_server.go:52] waiting for apiserver process to appear ...
I0825 11:33:28.891784   48115 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0825 11:33:28.909919   48115 api_server.go:72] duration metric: took 196.732916ms to wait for apiserver process to appear ...
I0825 11:33:28.909937   48115 api_server.go:88] waiting for apiserver healthz status ...
I0825 11:33:28.909943   48115 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:61133/healthz ...
I0825 11:33:28.914549   48115 api_server.go:279] https://127.0.0.1:61133/healthz returned 200:
ok
I0825 11:33:28.915727   48115 api_server.go:141] control plane version: v1.27.4
I0825 11:33:28.915731   48115 api_server.go:131] duration metric: took 5.7925ms to wait for apiserver health ...
I0825 11:33:28.915734   48115 system_pods.go:43] waiting for kube-system pods to appear ...
I0825 11:33:28.917005   48115 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0825 11:33:28.919834   48115 system_pods.go:59] 7 kube-system pods found
I0825 11:33:28.919843   48115 system_pods.go:61] "coredns-5d78c9869d-h4kwc" [4f77c13d-0ff2-46d1-8522-a5eb4023ebef] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0825 11:33:28.919849   48115 system_pods.go:61] "etcd-minikube" [0409753f-7e4a-4f5f-ac49-1e905a247e72] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0825 11:33:28.919852   48115 system_pods.go:61] "kube-apiserver-minikube" [5cb5f97d-0c4e-4d6c-9c4e-544fef89ba89] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0825 11:33:28.919855   48115 system_pods.go:61] "kube-controller-manager-minikube" [72c97442-cd76-4062-ac31-787a0f72451b] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0825 11:33:28.919857   48115 system_pods.go:61] "kube-proxy-nqbsc" [1f9278a2-6f04-42fd-8270-5fdee87ec062] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0825 11:33:28.919859   48115 system_pods.go:61] "kube-scheduler-minikube" [c0dd31ac-e2ce-41c0-aaf4-c7e79a5ed43d] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0825 11:33:28.919861   48115 system_pods.go:61] "storage-provisioner" [f629fc57-ef1b-4b6f-a816-d012ca8331d1] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0825 11:33:28.919864   48115 system_pods.go:74] duration metric: took 4.127667ms to wait for pod list to return data ...
I0825 11:33:28.919868   48115 kubeadm.go:581] duration metric: took 206.687875ms to wait for : map[apiserver:true system_pods:true] ...
I0825 11:33:28.919874   48115 node_conditions.go:102] verifying NodePressure condition ...
I0825 11:33:28.923723   48115 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I0825 11:33:28.923729   48115 node_conditions.go:123] node cpu capacity is 4
I0825 11:33:28.923733   48115 node_conditions.go:105] duration metric: took 3.857667ms to run NodePressure ...
I0825 11:33:28.923739   48115 start.go:228] waiting for startup goroutines ...
I0825 11:33:28.936610   48115 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0825 11:33:29.684611   48115 out.go:177] 🌟  Enabled addons: storage-provisioner, default-storageclass
I0825 11:33:29.694601   48115 addons.go:502] enable addons completed in 1.035466s: enabled=[storage-provisioner default-storageclass]
I0825 11:33:29.694657   48115 start.go:233] waiting for cluster config update ...
I0825 11:33:29.694701   48115 start.go:242] writing updated cluster config ...
I0825 11:33:29.701390   48115 ssh_runner.go:195] Run: rm -f paused
I0825 11:33:29.758622   48115 start.go:600] kubectl: 1.27.2, cluster: 1.27.4 (minor skew: 0)
I0825 11:33:29.763706   48115 out.go:177] 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Aug 28 03:13:00 minikube dockerd[1085]: time="2023-08-28T03:13:00.789913801Z" level=info msg="ignoring event" container=fcfd5ad63e6e14b96854d303e46d3fe9080e63733333f0f1951551288fe3c345 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:13:01 minikube cri-dockerd[1329]: time="2023-08-28T03:13:01Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/372b4afe9b8d9c76585a6529bf1b19b7173f0e68e39bfa67d206a8cbd48c44e0/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:13:01 minikube cri-dockerd[1329]: time="2023-08-28T03:13:01Z" level=info msg="Stop pulling image nginx:1.18-perl: Status: Image is up to date for nginx:1.18-perl"
Aug 28 03:13:01 minikube dockerd[1085]: time="2023-08-28T03:13:01.806045427Z" level=info msg="ignoring event" container=8668238bab99202ebab5a69c1dd45460244610f4cf4ed6627bf747dddf8652dc module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:13:01 minikube dockerd[1085]: time="2023-08-28T03:13:01.883994302Z" level=info msg="ignoring event" container=83ced0b161a8f7d493784bf5ffdd0c27a9d9200b4a2b4f7b171ab9e09f41cf21 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:13:02 minikube cri-dockerd[1329]: time="2023-08-28T03:13:02Z" level=info msg="Stop pulling image nginx:1.18-perl: Status: Image is up to date for nginx:1.18-perl"
Aug 28 03:13:02 minikube dockerd[1085]: time="2023-08-28T03:13:02.792009386Z" level=info msg="ignoring event" container=3cb99ba10f4f23d398dc5282e72623192e127c129ddbac31306031002dec3d34 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:13:02 minikube dockerd[1085]: time="2023-08-28T03:13:02.850390719Z" level=info msg="ignoring event" container=95ed158ac551e685a1a30970ad0b1616a82fffdf8ba33ff07edf10cf71e88c99 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:29 minikube dockerd[1085]: time="2023-08-28T03:15:29.794418176Z" level=info msg="ignoring event" container=b276462d405da35a082d5244f1c74a0f66880eba058e98184e30f46142c0fb15 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:29 minikube dockerd[1085]: time="2023-08-28T03:15:29.875824134Z" level=info msg="ignoring event" container=372b4afe9b8d9c76585a6529bf1b19b7173f0e68e39bfa67d206a8cbd48c44e0 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:30 minikube cri-dockerd[1329]: time="2023-08-28T03:15:30Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c3477c1f119f7feb138ada169c93653e23014d32e4f3a25bdc889faab515cfdb/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:30 minikube cri-dockerd[1329]: time="2023-08-28T03:15:30Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/8f4bbf91bb5c71d211f4ca2984466f05990ae87140e67bd76d6710a41c13d29f/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:30 minikube cri-dockerd[1329]: time="2023-08-28T03:15:30Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/8b4748546c4deae96684cabdb016538b23ce93289211f1ecd407a8390a791f5e/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:31 minikube cri-dockerd[1329]: time="2023-08-28T03:15:31Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:15:32 minikube cri-dockerd[1329]: time="2023-08-28T03:15:32Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:15:32 minikube dockerd[1085]: time="2023-08-28T03:15:32.485232677Z" level=info msg="ignoring event" container=84df65ddd2e5def062c1b4de7f925944439e0ae5bf2885668546fa5440214cd4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:32 minikube dockerd[1085]: time="2023-08-28T03:15:32.547539677Z" level=info msg="ignoring event" container=342b49a1c922d3fd7ceeb36bc85a9f32162f24fe085068b6a81b785691c45acc module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:32 minikube cri-dockerd[1329]: time="2023-08-28T03:15:32Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c96171d0b42629b70122c13dee766f7f46a0863258f5977a46e213280f16bad2/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:33 minikube cri-dockerd[1329]: time="2023-08-28T03:15:33Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:15:33 minikube dockerd[1085]: time="2023-08-28T03:15:33.510570511Z" level=info msg="ignoring event" container=7d9de720aded3a537d9cf3ebc33da53a8a029e4928582a7cf2be60511eefd4f4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:33 minikube dockerd[1085]: time="2023-08-28T03:15:33.561460136Z" level=info msg="ignoring event" container=d1dcf16375cb9a9f2587c8ad7fe0fad0ba75e069b771ba9131359827a4afc77a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:33 minikube dockerd[1085]: time="2023-08-28T03:15:33.615867636Z" level=info msg="ignoring event" container=f78a6d0242ab0796ac711fa8416705df62a0b636198146df391003e70161fdda module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:33 minikube dockerd[1085]: time="2023-08-28T03:15:33.623566719Z" level=info msg="ignoring event" container=5f7ca83f6210a85fe6c337ab46597af07a1d98d41e8f103187981a0df4afeb48 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:33 minikube cri-dockerd[1329]: time="2023-08-28T03:15:33Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1c113df6f8b4f029fd0e273616633ffdd9d823ee5c5eb10c62daf1b797790824/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:33 minikube cri-dockerd[1329]: time="2023-08-28T03:15:33Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/705d140c14d9e56d84f8f7cc866f67a799d7cef2aad5994466c6789990ae8a7e/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:15:34 minikube cri-dockerd[1329]: time="2023-08-28T03:15:34Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:15:34 minikube dockerd[1085]: time="2023-08-28T03:15:34.569224637Z" level=info msg="ignoring event" container=204a176d0f276e37892fb314cc6abafaf305ce70e7a59d8615728ff9508300d4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:34 minikube dockerd[1085]: time="2023-08-28T03:15:34.643711928Z" level=info msg="ignoring event" container=915fc162fff0efa292efae0ef42168d8148b5e5190aefb097e81596894d6905b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:35 minikube cri-dockerd[1329]: time="2023-08-28T03:15:35Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:15:35 minikube dockerd[1085]: time="2023-08-28T03:15:35.599483679Z" level=info msg="ignoring event" container=7c16523ae8f7a81a089fb227c45dc8043e17b65a07baa4075cbacdbbd9483586 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:35 minikube dockerd[1085]: time="2023-08-28T03:15:35.664341595Z" level=info msg="ignoring event" container=19c7e8094068fcc3fd9d416c2d1860bf5e432ff88d841508351d30fff269abf6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:15:36 minikube cri-dockerd[1329]: time="2023-08-28T03:15:36Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"
Aug 28 03:18:56 minikube dockerd[1085]: time="2023-08-28T03:18:56.299603341Z" level=info msg="ignoring event" container=f506e6c9a8b479a410e8e205fce807dd2411ac194e5882cd8d458a0b5954ebe5 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:18:56 minikube dockerd[1085]: time="2023-08-28T03:18:56.363365466Z" level=info msg="ignoring event" container=705d140c14d9e56d84f8f7cc866f67a799d7cef2aad5994466c6789990ae8a7e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:18:56 minikube cri-dockerd[1329]: time="2023-08-28T03:18:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e0d3926d45358f074ecf17e1d83dcd71747d36c55f7f6e18829766a621d6efb6/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:18:56 minikube cri-dockerd[1329]: time="2023-08-28T03:18:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/8ea56cd7f8e7fd799d99308d8742875b400cd1d055b400347dc152bd8885f127/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:18:56 minikube cri-dockerd[1329]: time="2023-08-28T03:18:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9df4b4ca212e21a122a55072c66fbc6d73d54fb1ff4a465b49cc60d8fed80fb0/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:18:58 minikube dockerd[1085]: time="2023-08-28T03:18:58.028944758Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:18:59 minikube dockerd[1085]: time="2023-08-28T03:18:59.210934676Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:00 minikube dockerd[1085]: time="2023-08-28T03:19:00.407164968Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:10 minikube dockerd[1085]: time="2023-08-28T03:19:10.837049417Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:13 minikube dockerd[1085]: time="2023-08-28T03:19:13.852456627Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:17 minikube dockerd[1085]: time="2023-08-28T03:19:17.898963587Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:33 minikube dockerd[1085]: time="2023-08-28T03:19:33.831901720Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:42 minikube dockerd[1085]: time="2023-08-28T03:19:42.762486710Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:19:46 minikube dockerd[1085]: time="2023-08-28T03:19:46.807139795Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:20:15 minikube dockerd[1085]: time="2023-08-28T03:20:15.887989836Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:20:32 minikube dockerd[1085]: time="2023-08-28T03:20:32.814838302Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:20:35 minikube dockerd[1085]: time="2023-08-28T03:20:35.845237929Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:21:41 minikube dockerd[1085]: time="2023-08-28T03:21:41.902762501Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:21:54 minikube dockerd[1085]: time="2023-08-28T03:21:54.834756257Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:22:10 minikube dockerd[1085]: time="2023-08-28T03:22:10.906107250Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:24:32 minikube dockerd[1085]: time="2023-08-28T03:24:32.914448052Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:24:47 minikube dockerd[1085]: time="2023-08-28T03:24:47.788894962Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:24:55 minikube dockerd[1085]: time="2023-08-28T03:24:55.805155007Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Aug 28 03:25:04 minikube dockerd[1085]: time="2023-08-28T03:25:04.658363845Z" level=info msg="ignoring event" container=e0d3926d45358f074ecf17e1d83dcd71747d36c55f7f6e18829766a621d6efb6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:25:04 minikube dockerd[1085]: time="2023-08-28T03:25:04.658724803Z" level=info msg="ignoring event" container=8ea56cd7f8e7fd799d99308d8742875b400cd1d055b400347dc152bd8885f127 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:25:04 minikube dockerd[1085]: time="2023-08-28T03:25:04.673423637Z" level=info msg="ignoring event" container=9df4b4ca212e21a122a55072c66fbc6d73d54fb1ff4a465b49cc60d8fed80fb0 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 28 03:25:05 minikube cri-dockerd[1329]: time="2023-08-28T03:25:05Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/f1ec0166365de6a3bdcab195c128ebcdbd1d3519a8b0694e25342c47f5df92e9/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Aug 28 03:25:06 minikube cri-dockerd[1329]: time="2023-08-28T03:25:06Z" level=info msg="Stop pulling image nginx:1.18: Status: Image is up to date for nginx:1.18"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                           CREATED             STATE               NAME                        ATTEMPT             POD ID              POD
7702c83580457       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   f1ec0166365de       myapp-deployment-58cc9787f7-mg2gp
f87460ea99644       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   1c113df6f8b4f       myapp-deployment-58cc9787f7-4sp8t
6514ca0a23b0c       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   c96171d0b4262       myapp-deployment-58cc9787f7-7njnv
be378c2d87627       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   8f4bbf91bb5c7       myapp-deployment-58cc9787f7-2x7wq
d970a3893dada       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   c3477c1f119f7       myapp-deployment-58cc9787f7-pjkn5
985cec71ec7c3       nginx@sha256:e90ac5331fe095cea01b121a3627174b2e33e06e83720e9a934c7b8ccc9c55a0   3 days ago          Running             nginx                       0                   8b4748546c4de       myapp-deployment-58cc9787f7-bhh89
008a65a886036       ba04bb24b9575                                                                   6 days ago          Running             storage-provisioner         7                   de569c5db302a       storage-provisioner
d9c81e79daabd       a422e0e982356                                                                   6 days ago          Running             dashboard-metrics-scraper   7                   22bfdf985cd66       dashboard-metrics-scraper-5dd9cbfd69-9dlcg
28c8dc8b6feb9       20b332c9a70d8                                                                   6 days ago          Running             kubernetes-dashboard        6                   eada743ab669f       kubernetes-dashboard-5c5cfc8747-822rw
5f6f360c72cef       97e04611ad434                                                                   6 days ago          Running             coredns                     5                   10505a7d13837       coredns-5d78c9869d-h4kwc
ef9df00ca9b59       a422e0e982356                                                                   6 days ago          Exited              dashboard-metrics-scraper   6                   674e35133831d       dashboard-metrics-scraper-5dd9cbfd69-9dlcg
df8f5fc93366a       ba04bb24b9575                                                                   6 days ago          Exited              storage-provisioner         6                   de569c5db302a       storage-provisioner
f6f073907dabe       97e04611ad434                                                                   6 days ago          Exited              coredns                     4                   65cf8b9935efc       coredns-5d78c9869d-h4kwc
c4b15831b0957       532e5a30e948f                                                                   6 days ago          Running             kube-proxy                  3                   21b91e22889d8       kube-proxy-nqbsc
6ad8bc26a696b       20b332c9a70d8                                                                   6 days ago          Exited              kubernetes-dashboard        5                   b636ace0432e2       kubernetes-dashboard-5c5cfc8747-822rw
983a4aa10b91d       64aece92d6bde                                                                   6 days ago          Running             kube-apiserver              3                   ced344285888f       kube-apiserver-minikube
6e11db6e2fb06       24bc64e911039                                                                   6 days ago          Running             etcd                        3                   5bf2de1f7deb6       etcd-minikube
71c494c324ee0       6eb63895cb67f                                                                   6 days ago          Running             kube-scheduler              3                   8bdcb67903ccd       kube-scheduler-minikube
8bfdb2832687a       389f6f052cf83                                                                   6 days ago          Running             kube-controller-manager     3                   82d8ec9ec9b23       kube-controller-manager-minikube
aa0e4224dc5cd       532e5a30e948f                                                                   6 days ago          Exited              kube-proxy                  2                   4c242088ed591       kube-proxy-nqbsc
1fc79a4103fe1       6eb63895cb67f                                                                   6 days ago          Exited              kube-scheduler              2                   1087a92741458       kube-scheduler-minikube
aae3192376354       24bc64e911039                                                                   6 days ago          Exited              etcd                        2                   f9ec9dc0ba46f       etcd-minikube
38d3500bcd835       64aece92d6bde                                                                   6 days ago          Exited              kube-apiserver              2                   ab85b2b2e5392       kube-apiserver-minikube
0ce01b7315189       389f6f052cf83                                                                   6 days ago          Exited              kube-controller-manager     2                   d8c61e7133794       kube-controller-manager-minikube

* 
* ==> coredns [5f6f360c72ce] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:44872 - 7345 "HINFO IN 4414094134989162716.8746806420647060584. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.286590917s

* 
* ==> coredns [f6f073907dab] <==
* [INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] plugin/health: Going into lameduck mode for 5s
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": dial tcp 10.96.0.1:443: connect: network is unreachable
[INFO] 127.0.0.1:41754 - 14851 "HINFO IN 7420233765320840729.4918957661218055032. udp 57 false 512" - - 0 5.000047503s
[ERROR] plugin/errors: 2 7420233765320840729.4918957661218055032. HINFO: dial udp 192.168.65.254:53: connect: network is unreachable
[INFO] 127.0.0.1:50507 - 28497 "HINFO IN 7420233765320840729.4918957661218055032. udp 57 false 512" - - 0 5.000032419s
[ERROR] plugin/errors: 2 7420233765320840729.4918957661218055032. HINFO: dial udp 192.168.65.254:53: connect: network is unreachable

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=fd7ecd9c4599bef9f04c0986c4a0187f98a4396e
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_08_20T21_32_58_0700
                    minikube.k8s.io/version=v1.31.2
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Mon, 21 Aug 2023 04:32:55 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Fri, 01 Sep 2023 02:42:51 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Fri, 01 Sep 2023 02:42:42 +0000   Mon, 21 Aug 2023 04:32:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Fri, 01 Sep 2023 02:42:42 +0000   Mon, 21 Aug 2023 04:32:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Fri, 01 Sep 2023 02:42:42 +0000   Mon, 21 Aug 2023 04:32:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Fri, 01 Sep 2023 02:42:42 +0000   Mon, 21 Aug 2023 04:32:56 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             8039992Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             8039992Ki
  pods:               110
System Info:
  Machine ID:                 e043b21f80e0460ca5d04cd00d06257d
  System UUID:                e043b21f80e0460ca5d04cd00d06257d
  Boot ID:                    114133be-24d7-4b63-8671-f669c8990461
  Kernel Version:             5.15.49-linuxkit-pr
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.4
  Kube-Proxy Version:         v1.27.4
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (15 in total)
  Namespace                   Name                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                          ------------  ----------  ---------------  -------------  ---
  default                     myapp-deployment-58cc9787f7-2x7wq             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  default                     myapp-deployment-58cc9787f7-4sp8t             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  default                     myapp-deployment-58cc9787f7-7njnv             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  default                     myapp-deployment-58cc9787f7-bhh89             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  default                     myapp-deployment-58cc9787f7-mg2gp             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  default                     myapp-deployment-58cc9787f7-pjkn5             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3d23h
  kube-system                 coredns-5d78c9869d-h4kwc                      100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (0%!)(MISSING)        170Mi (2%!)(MISSING)     10d
  kube-system                 etcd-minikube                                 100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (1%!)(MISSING)       0 (0%!)(MISSING)         10d
  kube-system                 kube-apiserver-minikube                       250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kube-system                 kube-controller-manager-minikube              200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kube-system                 kube-proxy-nqbsc                              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kube-system                 kube-scheduler-minikube                       100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kube-system                 storage-provisioner                           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kubernetes-dashboard        dashboard-metrics-scraper-5dd9cbfd69-9dlcg    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
  kubernetes-dashboard        kubernetes-dashboard-5c5cfc8747-822rw         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (18%!)(MISSING)  0 (0%!)(MISSING)
  memory             170Mi (2%!)(MISSING)  170Mi (2%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:              <none>

* 
* ==> dmesg <==
* [Aug26 06:31] cacheinfo: Unable to detect cache hierarchy for CPU 0
[  +0.006956] the cryptoloop driver has been deprecated and will be removed in in Linux 5.16
[  +0.004292] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +4.494817] FAT-fs (loop0): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.000378] FAT-fs (loop0): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.414661] grpcfuse: loading out-of-tree module taints kernel.
[Aug27 02:25] hrtimer: interrupt took 5730791 ns

* 
* ==> etcd [6e11db6e2fb0] <==
* {"level":"info","ts":"2023-08-31T13:41:18.371Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":294076}
{"level":"info","ts":"2023-08-31T13:41:18.373Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":294076,"took":"1.139375ms","hash":1776271324}
{"level":"info","ts":"2023-08-31T13:41:18.373Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1776271324,"revision":294076,"compact-revision":293837}
{"level":"info","ts":"2023-08-31T13:46:18.388Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":294314}
{"level":"info","ts":"2023-08-31T13:46:18.391Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":294314,"took":"1.706458ms","hash":174273687}
{"level":"info","ts":"2023-08-31T13:46:18.391Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":174273687,"revision":294314,"compact-revision":294076}
{"level":"info","ts":"2023-08-31T13:51:18.408Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":294554}
{"level":"info","ts":"2023-08-31T13:51:18.410Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":294554,"took":"1.138708ms","hash":3906754878}
{"level":"info","ts":"2023-08-31T13:51:18.410Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3906754878,"revision":294554,"compact-revision":294314}
{"level":"info","ts":"2023-08-31T15:08:59.915Z","caller":"traceutil/trace.go:171","msg":"trace[2099016273] linearizableReadLoop","detail":"{readStateIndex:369721; appliedIndex:369720; }","duration":"101.617416ms","start":"2023-08-31T15:08:59.813Z","end":"2023-08-31T15:08:59.915Z","steps":["trace[2099016273] 'read index received'  (duration: 101.244958ms)","trace[2099016273] 'applied index is now lower than readState.Index'  (duration: 369.333µs)"],"step_count":2}
{"level":"info","ts":"2023-08-31T15:08:59.915Z","caller":"traceutil/trace.go:171","msg":"trace[393035245] transaction","detail":"{read_only:false; response_revision:294947; number_of_response:1; }","duration":"105.825375ms","start":"2023-08-31T15:08:59.809Z","end":"2023-08-31T15:08:59.915Z","steps":["trace[393035245] 'process raft request'  (duration: 105.550792ms)"],"step_count":1}
{"level":"warn","ts":"2023-08-31T15:08:59.915Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"101.823041ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-08-31T15:08:59.915Z","caller":"traceutil/trace.go:171","msg":"trace[189832707] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:294947; }","duration":"102.111584ms","start":"2023-08-31T15:08:59.813Z","end":"2023-08-31T15:08:59.915Z","steps":["trace[189832707] 'agreement among raft nodes before linearized reading'  (duration: 101.786959ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:36:53.299Z","caller":"traceutil/trace.go:171","msg":"trace[1938376087] transaction","detail":"{read_only:false; response_revision:294967; number_of_response:1; }","duration":"119.826125ms","start":"2023-08-31T15:36:53.179Z","end":"2023-08-31T15:36:53.299Z","steps":["trace[1938376087] 'process raft request'  (duration: 119.724625ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:37:08.161Z","caller":"traceutil/trace.go:171","msg":"trace[1323002175] linearizableReadLoop","detail":"{readStateIndex:369761; appliedIndex:369760; }","duration":"113.093542ms","start":"2023-08-31T15:37:08.047Z","end":"2023-08-31T15:37:08.161Z","steps":["trace[1323002175] 'read index received'  (duration: 112.849292ms)","trace[1323002175] 'applied index is now lower than readState.Index'  (duration: 244.042µs)"],"step_count":2}
{"level":"info","ts":"2023-08-31T15:37:08.161Z","caller":"traceutil/trace.go:171","msg":"trace[1970452925] transaction","detail":"{read_only:false; response_revision:294979; number_of_response:1; }","duration":"113.970292ms","start":"2023-08-31T15:37:08.047Z","end":"2023-08-31T15:37:08.161Z","steps":["trace[1970452925] 'process raft request'  (duration: 113.667125ms)"],"step_count":1}
{"level":"warn","ts":"2023-08-31T15:37:08.161Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"113.329834ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/serviceaccounts/kube-system/generic-garbage-collector\" ","response":"range_response_count:1 size:217"}
{"level":"info","ts":"2023-08-31T15:37:08.161Z","caller":"traceutil/trace.go:171","msg":"trace[2026088843] range","detail":"{range_begin:/registry/serviceaccounts/kube-system/generic-garbage-collector; range_end:; response_count:1; response_revision:294979; }","duration":"113.379251ms","start":"2023-08-31T15:37:08.047Z","end":"2023-08-31T15:37:08.161Z","steps":["trace[2026088843] 'agreement among raft nodes before linearized reading'  (duration: 113.222959ms)"],"step_count":1}
{"level":"warn","ts":"2023-08-31T15:37:08.161Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"110.242792ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/serviceaccounts/kube-system/resourcequota-controller\" ","response":"range_response_count:1 size:215"}
{"level":"info","ts":"2023-08-31T15:37:08.161Z","caller":"traceutil/trace.go:171","msg":"trace[1198301231] range","detail":"{range_begin:/registry/serviceaccounts/kube-system/resourcequota-controller; range_end:; response_count:1; response_revision:294979; }","duration":"110.286417ms","start":"2023-08-31T15:37:08.051Z","end":"2023-08-31T15:37:08.161Z","steps":["trace[1198301231] 'agreement among raft nodes before linearized reading'  (duration: 110.150875ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:38:24.643Z","caller":"traceutil/trace.go:171","msg":"trace[1374556618] transaction","detail":"{read_only:false; response_revision:294984; number_of_response:1; }","duration":"103.815126ms","start":"2023-08-31T15:38:24.539Z","end":"2023-08-31T15:38:24.643Z","steps":["trace[1374556618] 'process raft request'  (duration: 103.599417ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:38:43.226Z","caller":"traceutil/trace.go:171","msg":"trace[2039381067] transaction","detail":"{read_only:false; response_revision:294999; number_of_response:1; }","duration":"106.452584ms","start":"2023-08-31T15:38:43.120Z","end":"2023-08-31T15:38:43.226Z","steps":["trace[2039381067] 'process raft request'  (duration: 106.307959ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:41:49.887Z","caller":"traceutil/trace.go:171","msg":"trace[1811491104] transaction","detail":"{read_only:false; response_revision:295027; number_of_response:1; }","duration":"102.138959ms","start":"2023-08-31T15:41:49.785Z","end":"2023-08-31T15:41:49.887Z","steps":["trace[1811491104] 'process raft request'  (duration: 101.898334ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T15:41:51.381Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":294793}
{"level":"info","ts":"2023-08-31T15:41:51.382Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":294793,"took":"1.407916ms","hash":389348645}
{"level":"info","ts":"2023-08-31T15:41:51.382Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":389348645,"revision":294793,"compact-revision":294554}
{"level":"info","ts":"2023-08-31T16:40:58.949Z","caller":"traceutil/trace.go:171","msg":"trace[1317628325] transaction","detail":"{read_only:false; response_revision:295060; number_of_response:1; }","duration":"130.073709ms","start":"2023-08-31T16:40:58.819Z","end":"2023-08-31T16:40:58.949Z","steps":["trace[1317628325] 'process raft request'  (duration: 128.105542ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T17:32:28.085Z","caller":"traceutil/trace.go:171","msg":"trace[188012607] transaction","detail":"{read_only:false; response_revision:295088; number_of_response:1; }","duration":"107.738709ms","start":"2023-08-31T17:32:27.977Z","end":"2023-08-31T17:32:28.085Z","steps":["trace[188012607] 'process raft request'  (duration: 107.404459ms)"],"step_count":1}
{"level":"warn","ts":"2023-08-31T17:32:28.085Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"107.120583ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-08-31T17:32:28.085Z","caller":"traceutil/trace.go:171","msg":"trace[1066330930] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:295088; }","duration":"107.351625ms","start":"2023-08-31T17:32:27.978Z","end":"2023-08-31T17:32:28.085Z","steps":["trace[1066330930] 'agreement among raft nodes before linearized reading'  (duration: 107.039583ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T17:32:28.085Z","caller":"traceutil/trace.go:171","msg":"trace[499392099] linearizableReadLoop","detail":"{readStateIndex:369898; appliedIndex:369897; }","duration":"106.860875ms","start":"2023-08-31T17:32:27.978Z","end":"2023-08-31T17:32:28.085Z","steps":["trace[499392099] 'read index received'  (duration: 106.572292ms)","trace[499392099] 'applied index is now lower than readState.Index'  (duration: 288.208µs)"],"step_count":2}
{"level":"info","ts":"2023-08-31T19:33:50.696Z","caller":"traceutil/trace.go:171","msg":"trace[1979729451] transaction","detail":"{read_only:false; response_revision:295145; number_of_response:1; }","duration":"105.415167ms","start":"2023-08-31T19:33:50.591Z","end":"2023-08-31T19:33:50.696Z","steps":["trace[1979729451] 'process raft request'  (duration: 105.212ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T22:15:54.805Z","caller":"etcdserver/server.go:1395","msg":"triggering snapshot","local-member-id":"aec36adc501070cc","local-member-applied-index":370037,"local-member-snapshot-index":360036,"local-member-snapshot-count":10000}
{"level":"info","ts":"2023-08-31T22:15:54.812Z","caller":"etcdserver/server.go:2413","msg":"saved snapshot","snapshot-index":370037}
{"level":"info","ts":"2023-08-31T22:15:54.813Z","caller":"etcdserver/server.go:2443","msg":"compacted Raft logs","compact-index":365037}
{"level":"info","ts":"2023-08-31T22:16:21.171Z","caller":"fileutil/purge.go:85","msg":"purged","path":"/var/lib/minikube/etcd/member/snap/0000000000000005-000000000004e220.snap"}
{"level":"info","ts":"2023-08-31T22:58:26.260Z","caller":"traceutil/trace.go:171","msg":"trace[1439674678] linearizableReadLoop","detail":"{readStateIndex:370083; appliedIndex:370082; }","duration":"108.424708ms","start":"2023-08-31T22:58:26.151Z","end":"2023-08-31T22:58:26.260Z","steps":["trace[1439674678] 'read index received'  (duration: 108.3035ms)","trace[1439674678] 'applied index is now lower than readState.Index'  (duration: 120.667µs)"],"step_count":2}
{"level":"warn","ts":"2023-08-31T22:58:26.260Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"108.613834ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-08-31T22:58:26.260Z","caller":"traceutil/trace.go:171","msg":"trace[851962204] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:295235; }","duration":"108.735375ms","start":"2023-08-31T22:58:26.151Z","end":"2023-08-31T22:58:26.260Z","steps":["trace[851962204] 'agreement among raft nodes before linearized reading'  (duration: 108.592833ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T23:03:30.622Z","caller":"traceutil/trace.go:171","msg":"trace[1276116101] transaction","detail":"{read_only:false; response_revision:295249; number_of_response:1; }","duration":"105.849959ms","start":"2023-08-31T23:03:30.516Z","end":"2023-08-31T23:03:30.622Z","steps":["trace[1276116101] 'process raft request'  (duration: 105.582042ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T23:03:54.556Z","caller":"traceutil/trace.go:171","msg":"trace[1157422887] linearizableReadLoop","detail":"{readStateIndex:370123; appliedIndex:370122; }","duration":"119.648625ms","start":"2023-08-31T23:03:54.437Z","end":"2023-08-31T23:03:54.556Z","steps":["trace[1157422887] 'read index received'  (duration: 119.550708ms)","trace[1157422887] 'applied index is now lower than readState.Index'  (duration: 97.042µs)"],"step_count":2}
{"level":"warn","ts":"2023-08-31T23:03:54.557Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"120.039ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csinodes/\" range_end:\"/registry/csinodes0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2023-08-31T23:03:54.557Z","caller":"traceutil/trace.go:171","msg":"trace[618401488] range","detail":"{range_begin:/registry/csinodes/; range_end:/registry/csinodes0; response_count:0; response_revision:295267; }","duration":"120.200208ms","start":"2023-08-31T23:03:54.437Z","end":"2023-08-31T23:03:54.557Z","steps":["trace[618401488] 'agreement among raft nodes before linearized reading'  (duration: 119.816333ms)"],"step_count":1}
{"level":"warn","ts":"2023-08-31T23:03:54.557Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"115.039ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-08-31T23:03:54.557Z","caller":"traceutil/trace.go:171","msg":"trace[768638881] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:295268; }","duration":"115.138917ms","start":"2023-08-31T23:03:54.442Z","end":"2023-08-31T23:03:54.557Z","steps":["trace[768638881] 'agreement among raft nodes before linearized reading'  (duration: 115.013042ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T23:03:54.557Z","caller":"traceutil/trace.go:171","msg":"trace[13992242] transaction","detail":"{read_only:false; response_revision:295268; number_of_response:1; }","duration":"120.906875ms","start":"2023-08-31T23:03:54.437Z","end":"2023-08-31T23:03:54.557Z","steps":["trace[13992242] 'process raft request'  (duration: 120.598333ms)"],"step_count":1}
{"level":"info","ts":"2023-08-31T23:03:54.560Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":295029}
{"level":"info","ts":"2023-08-31T23:03:54.562Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":295029,"took":"1.505ms","hash":19084507}
{"level":"info","ts":"2023-08-31T23:03:54.562Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":19084507,"revision":295029,"compact-revision":294793}
{"level":"info","ts":"2023-09-01T01:09:59.355Z","caller":"traceutil/trace.go:171","msg":"trace[146724909] transaction","detail":"{read_only:false; response_revision:295363; number_of_response:1; }","duration":"101.588125ms","start":"2023-09-01T01:09:59.254Z","end":"2023-09-01T01:09:59.355Z","steps":["trace[146724909] 'process raft request'  (duration: 101.484542ms)"],"step_count":1}
{"level":"info","ts":"2023-09-01T01:18:00.958Z","caller":"traceutil/trace.go:171","msg":"trace[2142420015] transaction","detail":"{read_only:false; response_revision:295387; number_of_response:1; }","duration":"100.389625ms","start":"2023-09-01T01:18:00.858Z","end":"2023-09-01T01:18:00.958Z","steps":["trace[2142420015] 'process raft request'  (duration: 99.974959ms)"],"step_count":1}
{"level":"info","ts":"2023-09-01T01:46:49.912Z","caller":"traceutil/trace.go:171","msg":"trace[693452138] linearizableReadLoop","detail":"{readStateIndex:370282; appliedIndex:370281; }","duration":"118.485167ms","start":"2023-09-01T01:46:49.793Z","end":"2023-09-01T01:46:49.912Z","steps":["trace[693452138] 'read index received'  (duration: 52.583µs)","trace[693452138] 'applied index is now lower than readState.Index'  (duration: 118.431ms)"],"step_count":2}
{"level":"warn","ts":"2023-09-01T01:46:49.912Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"118.690125ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/endpointslices/\" range_end:\"/registry/endpointslices0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2023-09-01T01:46:49.912Z","caller":"traceutil/trace.go:171","msg":"trace[1831603045] range","detail":"{range_begin:/registry/endpointslices/; range_end:/registry/endpointslices0; response_count:0; response_revision:295393; }","duration":"118.866583ms","start":"2023-09-01T01:46:49.793Z","end":"2023-09-01T01:46:49.912Z","steps":["trace[1831603045] 'agreement among raft nodes before linearized reading'  (duration: 118.648541ms)"],"step_count":1}
{"level":"info","ts":"2023-09-01T02:34:07.240Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":295268}
{"level":"info","ts":"2023-09-01T02:34:07.246Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":295268,"took":"2.470583ms","hash":1605783185}
{"level":"info","ts":"2023-09-01T02:34:07.246Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1605783185,"revision":295268,"compact-revision":295029}
{"level":"info","ts":"2023-09-01T02:39:07.258Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":295506}
{"level":"info","ts":"2023-09-01T02:39:07.262Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":295506,"took":"2.741792ms","hash":628152716}
{"level":"info","ts":"2023-09-01T02:39:07.262Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":628152716,"revision":295506,"compact-revision":295268}

* 
* ==> etcd [aae319237635] <==
* {"level":"warn","ts":"2023-08-25T18:23:40.898Z","caller":"flags/flag.go:93","msg":"unrecognized environment variable","environment-variable":"ETCD_UNSUPPORTED_ARCH=arm64"}
{"level":"info","ts":"2023-08-25T18:23:40.898Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-08-25T18:23:40.899Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"info","ts":"2023-08-25T18:23:40.899Z","caller":"embed/etcd.go:124","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2023-08-25T18:23:40.900Z","caller":"embed/etcd.go:484","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-08-25T18:23:40.900Z","caller":"embed/etcd.go:132","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2023-08-25T18:23:40.900Z","caller":"embed/etcd.go:306","msg":"starting an etcd server","etcd-version":"3.5.7","git-sha":"215b53cf3","go-version":"go1.17.13","go-os":"linux","go-arch":"arm64","max-cpu-set":4,"max-cpu-available":4,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-08-25T18:23:40.901Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"1.155083ms"}
{"level":"info","ts":"2023-08-25T18:23:41.381Z","caller":"etcdserver/server.go:509","msg":"recovered v2 store from snapshot","snapshot-index":100010,"snapshot-size":"7.1 kB"}
{"level":"info","ts":"2023-08-25T18:23:41.382Z","caller":"etcdserver/server.go:522","msg":"recovered v3 backend from snapshot","backend-size-bytes":1593344,"backend-size":"1.6 MB","backend-size-in-use-bytes":1413120,"backend-size-in-use":"1.4 MB"}
{"level":"info","ts":"2023-08-25T18:23:41.393Z","caller":"etcdserver/raft.go:529","msg":"restarting local member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","commit-index":103480}
{"level":"info","ts":"2023-08-25T18:23:41.393Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2023-08-25T18:23:41.394Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 3"}
{"level":"info","ts":"2023-08-25T18:23:41.394Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [aec36adc501070cc], term: 3, commit: 103480, applied: 100010, lastindex: 103480, lastterm: 3]"}
{"level":"info","ts":"2023-08-25T18:23:41.394Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-08-25T18:23:41.394Z","caller":"membership/cluster.go:278","msg":"recovered/added member from store","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","recovered-remote-peer-id":"aec36adc501070cc","recovered-remote-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2023-08-25T18:23:41.394Z","caller":"membership/cluster.go:287","msg":"set cluster version from store","cluster-version":"3.5"}
{"level":"warn","ts":"2023-08-25T18:23:41.395Z","caller":"auth/store.go:1234","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-08-25T18:23:41.396Z","caller":"mvcc/kvstore.go:323","msg":"restored last compact revision","meta-bucket-name":"meta","meta-bucket-name-key":"finishedCompactRev","restored-compact-revision":82026}
{"level":"info","ts":"2023-08-25T18:23:41.397Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":82564}
{"level":"info","ts":"2023-08-25T18:23:41.399Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-08-25T18:23:41.399Z","caller":"etcdserver/corrupt.go:95","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2023-08-25T18:23:41.400Z","caller":"etcdserver/corrupt.go:165","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2023-08-25T18:23:41.400Z","caller":"etcdserver/server.go:845","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.7","cluster-id":"fa54960ea34d58be","cluster-version":"3.5"}
{"level":"info","ts":"2023-08-25T18:23:41.401Z","caller":"etcdserver/server.go:738","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-08-25T18:23:41.401Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-08-25T18:23:41.403Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-08-25T18:23:41.403Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-08-25T18:23:41.405Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-08-25T18:23:41.406Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-08-25T18:23:41.405Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-08-25T18:23:41.406Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-08-25T18:23:41.406Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-08-25T18:23:41.494Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 3"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 3"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 4"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 4"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 4"}
{"level":"info","ts":"2023-08-25T18:23:41.495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 4"}
{"level":"info","ts":"2023-08-25T18:23:41.497Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2023-08-25T18:23:41.497Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-08-25T18:23:41.498Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-08-25T18:23:41.498Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-08-25T18:23:41.498Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2023-08-25T18:23:41.499Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-08-25T18:23:41.499Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-08-25T18:32:50.179Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2023-08-25T18:32:50.179Z","caller":"embed/etcd.go:373","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"info","ts":"2023-08-25T18:32:50.191Z","caller":"etcdserver/server.go:1465","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2023-08-25T18:32:50.195Z","caller":"embed/etcd.go:568","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-08-25T18:32:50.196Z","caller":"embed/etcd.go:573","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-08-25T18:32:50.196Z","caller":"embed/etcd.go:375","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}

* 
* ==> kernel <==
*  02:42:56 up 5 days, 20:11,  0 users,  load average: 0.29, 0.68, 0.74
Linux minikube 5.15.49-linuxkit-pr #1 SMP PREEMPT Thu May 25 07:27:39 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [38d3500bcd83] <==
*   "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.194396       1 logging.go:59] [core] [Channel #121 SubChannel #122] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.194446       1 logging.go:59] [core] [Channel #157 SubChannel #158] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.194507       1 logging.go:59] [core] [Channel #103 SubChannel #104] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.194571       1 logging.go:59] [core] [Channel #40 SubChannel #41] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.194618       1 logging.go:59] [core] [Channel #100 SubChannel #101] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.192840       1 logging.go:59] [core] [Channel #1 SubChannel #2] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0825 18:32:51.195064       1 logging.go:59] [core] [Channel #109 SubChannel #110] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"

* 
* ==> kube-apiserver [983a4aa10b91] <==
* E0829 06:50:00.222725       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 10:07:56.477183       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 10:07:56.477652       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 12:19:08.935990       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 12:19:08.936214       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 15:06:08.347434       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 15:06:08.347684       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 17:21:52.933823       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 17:21:52.936772       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 19:59:08.269510       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 19:59:08.269528       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 21:40:12.508493       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 21:40:12.508964       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 22:51:50.820347       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0829 22:51:50.820627       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 00:13:29.878607       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 00:13:29.878607       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 04:27:22.814115       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 04:27:22.819651       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 12:00:58.997737       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 12:00:58.997746       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 14:32:14.607476       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 14:32:14.607477       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 16:28:41.490705       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 16:28:41.491122       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 18:06:54.625059       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 18:06:54.625239       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 19:59:38.526862       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 19:59:38.526864       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 23:33:52.539533       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0830 23:33:52.541556       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 00:58:57.643514       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 00:58:57.643524       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 02:05:14.132944       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 02:05:14.132947       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 03:10:00.287830       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 03:10:00.288312       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 04:22:45.316105       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 04:22:45.316131       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 05:39:29.660975       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 05:39:29.662859       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 08:23:08.108481       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 08:23:08.110122       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 10:53:51.198833       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 10:53:51.200773       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 15:09:10.693893       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 15:09:10.693900       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 16:41:15.694125       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 16:41:15.696476       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 18:38:49.779597       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 18:38:49.779819       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 20:40:51.532842       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 20:40:51.532859       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 22:58:32.694290       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0831 22:58:32.694352       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0901 00:21:38.032975       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0901 00:21:38.033563       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0901 01:47:06.860568       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0901 01:47:06.860613       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I0901 02:39:08.501656       1 alloc.go:330] "allocated clusterIPs" service="default/myapp-service" clusterIPs=map[IPv4:10.105.203.94]

* 
* ==> kube-controller-manager [0ce01b731518] <==
* I0825 18:23:55.242339       1 controllermanager.go:638] "Started controller" controller="attachdetach"
I0825 18:23:55.242517       1 attach_detach_controller.go:343] "Starting attach detach controller"
I0825 18:23:55.242535       1 shared_informer.go:311] Waiting for caches to sync for attach detach
I0825 18:23:55.243634       1 controllermanager.go:638] "Started controller" controller="root-ca-cert-publisher"
I0825 18:23:55.243722       1 publisher.go:101] Starting root CA certificate configmap publisher
I0825 18:23:55.243778       1 shared_informer.go:311] Waiting for caches to sync for crt configmap
I0825 18:23:55.244837       1 controllermanager.go:638] "Started controller" controller="endpointslice"
I0825 18:23:55.246541       1 endpointslice_controller.go:252] Starting endpoint slice controller
I0825 18:23:55.247368       1 shared_informer.go:311] Waiting for caches to sync for endpoint_slice
I0825 18:23:55.247827       1 shared_informer.go:311] Waiting for caches to sync for resource quota
I0825 18:23:55.254287       1 actual_state_of_world.go:547] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0825 18:23:55.260275       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I0825 18:23:55.276792       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I0825 18:23:55.277501       1 shared_informer.go:318] Caches are synced for stateful set
I0825 18:23:55.281505       1 shared_informer.go:318] Caches are synced for ephemeral
I0825 18:23:55.282747       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I0825 18:23:55.286723       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0825 18:23:55.286741       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I0825 18:23:55.286754       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I0825 18:23:55.286801       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I0825 18:23:55.287892       1 shared_informer.go:318] Caches are synced for persistent volume
I0825 18:23:55.287936       1 shared_informer.go:318] Caches are synced for namespace
I0825 18:23:55.290331       1 shared_informer.go:318] Caches are synced for expand
I0825 18:23:55.301730       1 shared_informer.go:318] Caches are synced for service account
I0825 18:23:55.302893       1 shared_informer.go:318] Caches are synced for deployment
I0825 18:23:55.303187       1 shared_informer.go:318] Caches are synced for TTL
I0825 18:23:55.304578       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0825 18:23:55.307050       1 shared_informer.go:318] Caches are synced for PVC protection
I0825 18:23:55.307529       1 shared_informer.go:318] Caches are synced for PV protection
I0825 18:23:55.325381       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0825 18:23:55.334107       1 shared_informer.go:318] Caches are synced for GC
I0825 18:23:55.334145       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I0825 18:23:55.334832       1 shared_informer.go:318] Caches are synced for endpoint
I0825 18:23:55.341858       1 shared_informer.go:318] Caches are synced for node
I0825 18:23:55.341870       1 shared_informer.go:318] Caches are synced for HPA
I0825 18:23:55.341914       1 range_allocator.go:174] "Sending events to api server"
I0825 18:23:55.341936       1 range_allocator.go:178] "Starting range CIDR allocator"
I0825 18:23:55.341944       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0825 18:23:55.341947       1 shared_informer.go:318] Caches are synced for cidrallocator
I0825 18:23:55.343157       1 shared_informer.go:318] Caches are synced for attach detach
I0825 18:23:55.344016       1 shared_informer.go:318] Caches are synced for crt configmap
I0825 18:23:55.347745       1 shared_informer.go:318] Caches are synced for endpoint_slice
I0825 18:23:55.379571       1 shared_informer.go:318] Caches are synced for cronjob
I0825 18:23:55.384159       1 shared_informer.go:318] Caches are synced for TTL after finished
I0825 18:23:55.385395       1 shared_informer.go:318] Caches are synced for job
I0825 18:23:55.448202       1 shared_informer.go:318] Caches are synced for resource quota
I0825 18:23:55.478173       1 shared_informer.go:318] Caches are synced for daemon sets
I0825 18:23:55.481088       1 shared_informer.go:318] Caches are synced for taint
I0825 18:23:55.481223       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0825 18:23:55.481331       1 taint_manager.go:211] "Sending events to api server"
I0825 18:23:55.481483       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I0825 18:23:55.481507       1 shared_informer.go:318] Caches are synced for ReplicationController
I0825 18:23:55.481610       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I0825 18:23:55.481670       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0825 18:23:55.481676       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I0825 18:23:55.492410       1 shared_informer.go:318] Caches are synced for disruption
I0825 18:23:55.500277       1 shared_informer.go:318] Caches are synced for resource quota
I0825 18:23:55.860549       1 shared_informer.go:318] Caches are synced for garbage collector
I0825 18:23:55.915849       1 shared_informer.go:318] Caches are synced for garbage collector
I0825 18:23:55.915872       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"

* 
* ==> kube-controller-manager [8bfdb2832687] <==
* W0829 06:50:00.222125       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 06:50:00.223289       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0829 10:07:56.478287       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 10:07:56.478286       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0829 12:19:08.936412       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0829 12:19:08.936602       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0829 15:06:08.348108       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 15:06:08.348703       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0829 17:21:52.935287       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0829 17:21:52.937280       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 19:59:08.270204       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0829 19:59:08.270264       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 21:40:12.510061       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0829 21:40:12.510184       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0829 22:51:50.820595       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0829 22:51:50.820922       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 00:13:29.879270       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 00:13:29.879449       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 04:27:22.821684       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 04:27:22.821729       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 12:00:58.998841       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 12:00:58.999148       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 14:32:14.608276       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 14:32:14.608297       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0830 16:28:41.491368       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 16:28:41.491437       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0830 18:06:54.625869       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 18:06:54.625884       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0830 19:59:38.527597       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 19:59:38.527663       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0830 23:33:52.543783       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0830 23:33:52.543941       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0831 00:58:57.644529       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 00:58:57.644646       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0831 02:05:14.135545       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 02:05:14.135691       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0831 03:10:00.288422       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 03:10:00.288918       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0831 04:22:45.316437       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 04:22:45.316444       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0831 05:39:29.673335       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 05:39:29.673374       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0831 08:23:08.111559       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 08:23:08.111988       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0831 10:53:51.200477       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 10:53:51.201663       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0831 15:09:10.695415       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 15:09:10.695381       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W0831 16:41:15.697958       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 16:41:15.698316       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 18:38:49.780433       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 18:38:49.780450       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 20:40:51.534171       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 20:40:51.534293       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0831 22:58:32.694868       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0831 22:58:32.694868       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E0901 00:21:38.034104       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0901 00:21:38.034123       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E0901 01:47:06.861383       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W0901 01:47:06.861425       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials

* 
* ==> kube-proxy [aa0e4224dc5c] <==
* I0825 18:23:43.912949       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0825 18:23:43.913016       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I0825 18:23:43.913033       1 server_others.go:554] "Using iptables proxy"
I0825 18:23:43.935022       1 server_others.go:192] "Using iptables Proxier"
I0825 18:23:43.935043       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0825 18:23:43.935047       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0825 18:23:43.935056       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0825 18:23:43.935114       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0825 18:23:43.935458       1 server.go:658] "Version info" version="v1.27.4"
I0825 18:23:43.935464       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0825 18:23:43.936705       1 config.go:188] "Starting service config controller"
I0825 18:23:43.936725       1 shared_informer.go:311] Waiting for caches to sync for service config
I0825 18:23:43.936734       1 config.go:97] "Starting endpoint slice config controller"
I0825 18:23:43.936735       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0825 18:23:43.936964       1 config.go:315] "Starting node config controller"
I0825 18:23:43.936970       1 shared_informer.go:311] Waiting for caches to sync for node config
I0825 18:23:44.036924       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0825 18:23:44.036967       1 shared_informer.go:318] Caches are synced for service config
I0825 18:23:44.037040       1 shared_informer.go:318] Caches are synced for node config

* 
* ==> kube-proxy [c4b15831b095] <==
* I0825 18:33:28.729380       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0825 18:33:28.729482       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I0825 18:33:28.729497       1 server_others.go:554] "Using iptables proxy"
I0825 18:33:28.832854       1 server_others.go:192] "Using iptables Proxier"
I0825 18:33:28.832876       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0825 18:33:28.832881       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0825 18:33:28.832889       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0825 18:33:28.832976       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0825 18:33:28.833419       1 server.go:658] "Version info" version="v1.27.4"
I0825 18:33:28.833424       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0825 18:33:28.835115       1 config.go:188] "Starting service config controller"
I0825 18:33:28.838087       1 shared_informer.go:311] Waiting for caches to sync for service config
I0825 18:33:28.838102       1 shared_informer.go:318] Caches are synced for service config
I0825 18:33:28.835310       1 config.go:97] "Starting endpoint slice config controller"
I0825 18:33:28.838114       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0825 18:33:28.835436       1 config.go:315] "Starting node config controller"
I0825 18:33:28.838120       1 shared_informer.go:311] Waiting for caches to sync for node config
I0825 18:33:28.838123       1 shared_informer.go:318] Caches are synced for node config
I0825 18:33:28.939344       1 shared_informer.go:318] Caches are synced for endpoint slice config

* 
* ==> kube-scheduler [1fc79a4103fe] <==
* I0825 18:23:41.604148       1 serving.go:348] Generated self-signed cert in-memory
W0825 18:23:42.405889       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0825 18:23:42.405907       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0825 18:23:42.405915       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0825 18:23:42.405919       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0825 18:23:42.431123       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I0825 18:23:42.431260       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0825 18:23:42.432408       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0825 18:23:42.432459       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0825 18:23:42.432757       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0825 18:23:42.432817       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0825 18:23:42.532681       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
E0825 18:32:50.227002       1 scheduling_queue.go:1139] "Error while retrieving next pod from scheduling queue" err="scheduling queue is closed"
E0825 18:32:50.227053       1 run.go:74] "command failed" err="finished without leader elect"

* 
* ==> kube-scheduler [71c494c324ee] <==
* I0825 18:33:25.086605       1 serving.go:348] Generated self-signed cert in-memory
W0825 18:33:26.708099       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0825 18:33:26.708124       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0825 18:33:26.708129       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0825 18:33:26.708132       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0825 18:33:26.717558       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I0825 18:33:26.717625       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0825 18:33:26.719034       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0825 18:33:26.719219       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0825 18:33:26.719280       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0825 18:33:26.719917       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0825 18:33:26.820710       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Aug 31 07:04:24 minikube kubelet[1693]: W0831 07:04:24.721701    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 07:04:24 minikube kubelet[1693]: W0831 07:04:24.724371    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 07:09:24 minikube kubelet[1693]: W0831 07:09:24.719451    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 07:09:24 minikube kubelet[1693]: W0831 07:09:24.725238    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 07:14:24 minikube kubelet[1693]: W0831 07:14:24.725732    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 07:14:24 minikube kubelet[1693]: W0831 07:14:24.728725    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:01:03 minikube kubelet[1693]: W0831 12:01:03.464675    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:01:03 minikube kubelet[1693]: W0831 12:01:03.467987    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:06:03 minikube kubelet[1693]: W0831 12:06:03.455745    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:06:03 minikube kubelet[1693]: W0831 12:06:03.456112    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:11:03 minikube kubelet[1693]: W0831 12:11:03.463489    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:11:03 minikube kubelet[1693]: W0831 12:11:03.468082    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:16:03 minikube kubelet[1693]: W0831 12:16:03.465488    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:16:03 minikube kubelet[1693]: W0831 12:16:03.466749    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:21:03 minikube kubelet[1693]: W0831 12:21:03.471133    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:21:03 minikube kubelet[1693]: W0831 12:21:03.472105    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:26:03 minikube kubelet[1693]: W0831 12:26:03.470055    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:26:03 minikube kubelet[1693]: W0831 12:26:03.470816    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:31:03 minikube kubelet[1693]: W0831 12:31:03.477274    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:31:03 minikube kubelet[1693]: W0831 12:31:03.479154    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:36:03 minikube kubelet[1693]: W0831 12:36:03.487026    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:36:03 minikube kubelet[1693]: W0831 12:36:03.488166    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:41:03 minikube kubelet[1693]: W0831 12:41:03.482839    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:41:03 minikube kubelet[1693]: W0831 12:41:03.483618    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:46:03 minikube kubelet[1693]: W0831 12:46:03.452092    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:46:03 minikube kubelet[1693]: W0831 12:46:03.452467    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:51:03 minikube kubelet[1693]: W0831 12:51:03.431625    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:51:03 minikube kubelet[1693]: W0831 12:51:03.431933    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 12:56:03 minikube kubelet[1693]: W0831 12:56:03.437452    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 12:56:03 minikube kubelet[1693]: W0831 12:56:03.443300    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:01:03 minikube kubelet[1693]: W0831 13:01:03.410876    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:01:03 minikube kubelet[1693]: W0831 13:01:03.414191    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:06:03 minikube kubelet[1693]: W0831 13:06:03.405819    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:06:03 minikube kubelet[1693]: W0831 13:06:03.407360    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:11:03 minikube kubelet[1693]: W0831 13:11:03.395521    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:11:03 minikube kubelet[1693]: W0831 13:11:03.396479    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:16:03 minikube kubelet[1693]: W0831 13:16:03.393677    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:16:03 minikube kubelet[1693]: W0831 13:16:03.395230    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:21:03 minikube kubelet[1693]: W0831 13:21:03.392940    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:21:03 minikube kubelet[1693]: W0831 13:21:03.394597    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:26:03 minikube kubelet[1693]: W0831 13:26:03.385948    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:26:03 minikube kubelet[1693]: W0831 13:26:03.388818    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:31:03 minikube kubelet[1693]: W0831 13:31:03.384400    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:31:03 minikube kubelet[1693]: W0831 13:31:03.385806    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:36:03 minikube kubelet[1693]: W0831 13:36:03.394141    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:36:03 minikube kubelet[1693]: W0831 13:36:03.394902    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:41:03 minikube kubelet[1693]: W0831 13:41:03.394883    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:41:03 minikube kubelet[1693]: W0831 13:41:03.395851    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:46:03 minikube kubelet[1693]: W0831 13:46:03.400188    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:46:03 minikube kubelet[1693]: W0831 13:46:03.403316    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 13:51:03 minikube kubelet[1693]: W0831 13:51:03.393080    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 13:51:03 minikube kubelet[1693]: W0831 13:51:03.394018    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 15:41:36 minikube kubelet[1693]: W0831 15:41:36.348294    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 15:41:36 minikube kubelet[1693]: W0831 15:41:36.349311    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Aug 31 23:03:39 minikube kubelet[1693]: W0831 23:03:39.265733    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Aug 31 23:03:39 minikube kubelet[1693]: W0831 23:03:39.267744    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Sep 01 02:33:51 minikube kubelet[1693]: W0901 02:33:51.939894    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Sep 01 02:33:51 minikube kubelet[1693]: W0901 02:33:51.941174    1693 machine.go:65] Cannot read vendor id correctly, set empty.
Sep 01 02:38:51 minikube kubelet[1693]: W0901 02:38:51.934121    1693 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Sep 01 02:38:51 minikube kubelet[1693]: W0901 02:38:51.935733    1693 machine.go:65] Cannot read vendor id correctly, set empty.

* 
* ==> storage-provisioner [008a65a88603] <==
* I0825 18:34:13.752606       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0825 18:34:13.758074       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0825 18:34:13.758176       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0825 18:34:31.211362       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0825 18:34:31.211680       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"d58192dc-60ae-46ed-b15e-afcf43ee68ed", APIVersion:"v1", ResourceVersion:"83461", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_cc8ae6b6-2e41-43e9-b97e-fa75362e9611 became leader
I0825 18:34:31.211966       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_cc8ae6b6-2e41-43e9-b97e-fa75362e9611!
I0825 18:34:31.313660       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_cc8ae6b6-2e41-43e9-b97e-fa75362e9611!

* 
* ==> storage-provisioner [df8f5fc93366] <==
* I0825 18:33:28.430604       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0825 18:33:58.434189       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout

